{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96b15bd-505d-43cb-a043-f696ce75e595",
   "metadata": {},
   "source": [
    "# Introduction to Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f3c47-5274-4e56-8d8c-7d7db89b3657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "def add_lags(df, columns, n_lags=1):\n",
    "    \"\"\"\n",
    "    Add lags to specific columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Original DataFrame.\n",
    "    - columns (list): List of column names for which to create lags.\n",
    "    - n_lags (int): Number of lags to create for each column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Updated DataFrame with lag columns.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            df[f\"{column}_lag{lag}\"] = df[column].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed496679-d308-4ee4-b82e-252348ba9d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Rv_daily_lec4.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0692fc6-03ff-4530-8e2a-f8e90b08876c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_to_transform = [\"TBill3M\", \"TBill1Y\", \"Oil\", \"Gold\", \"SP_volume\"]\n",
    "for c in col_to_transform:\n",
    "    df[\"{}_ret\".format(c)] = df[c].pct_change(1) * 100\n",
    "df = df.dropna()\n",
    "\n",
    "df = add_lags(df, [\"Return_close\"], n_lags=3)\n",
    "df = df.dropna()\n",
    "df = df.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1864b-0650-4d80-848e-9260a4c50ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2f8ce-d54c-46c6-9520-6f0b7e750dc5",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:24px\">\n",
    "    <span style=\"color:red\">How do we setup a classification problem?</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Click to expand!</summary>\n",
    "    \n",
    "    Define the Target Variable: Decide what you want to classify. For example, you might want to predict whether the \"Return_close\" is positive or negative. This would turn the problem into a binary classification task.\n",
    "\n",
    "    Convert the Target Variable: Based on the definition, you'll need to transform the \"Return_close\" into a binary variable. You can set a threshold (e.g., 0) and classify the returns as:\n",
    "\n",
    "    - 1 if \"Return_close\" > 0 (Positive Return)\n",
    "    - 0 if \"Return_close\" <= 0 (Negative Return or No Gain)\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d54b99-6b87-493f-b31a-099029021ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Ret_binary\"] = (df[\"Return_close\"] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf9c44-994b-44b0-a5ca-ba3c1661212d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Ret_binary\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c17334-954f-4af4-bfa2-c421c279034c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Ret_binary\"].value_counts()/df[\"Ret_binary\"].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4010edd-54f2-427f-85f1-ac1d58e36b98",
   "metadata": {},
   "source": [
    "## Logistic Regression for Binary Classification\n",
    "\n",
    "Logistic regression is a type of regression analysis used for binary classification problems, where the outcome variable (dependent variable) is binary, meaning it has only two possible values, often coded as 0 and 1. The output of logistic regression is quite different from linear regression, and its interpretation is distinct as well.\n",
    "\n",
    "### Output of Logistic Regression\n",
    "\n",
    "The output of logistic regression is a probability estimate that an observation belongs to the positive class (class 1). This probability is bounded between 0 and 1. Mathematically, logistic regression models the log-odds (logit) of the probability of the positive class. The logistic regression equation is typically expressed as:\n",
    "\n",
    "$$ \\text{Logit}(p) = \\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_px_p $$\n",
    "\n",
    "- $p$ represents the probability of the positive class.\n",
    "- $\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_p$ are the coefficients of the model.\n",
    "- $x_1, x_2, \\ldots, x_p$ are the input features.\n",
    "\n",
    "- To obtain the probability $p$ from the log-odds, we apply the inverse of the logit function, which is the logistic (sigmoid) function:\n",
    "\n",
    "$$\n",
    "p = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_px_p)}}\n",
    "$$\n",
    "\n",
    "This function ensures that the output is a probability value between 0 and 1. The logistic function takes the linear combination of the input features and their coefficients (the log-odds) and maps it to a probability, allowing us to interpret the model's predictions in terms of the likelihood that an observation belongs to the positive class.\n",
    "\n",
    "### Interpreting Logistic Regression\n",
    "\n",
    "1. **Coefficient Interpretation:** The coefficients ($\\beta$) in logistic regression represent the change in the log-odds of the probability of the positive class for a one-unit change in the corresponding predictor variable, while holding all other predictors constant. Unlike linear regression, where coefficients represent changes in the dependent variable, logistic regression coefficients are related to the log-odds of the outcome.\n",
    "\n",
    "2. **Probability Interpretation:** The probability estimate $p$ can be converted into class predictions. Commonly, a threshold of 0.5 is used; if $p > 0.5$, the observation is classified as the positive class, and if $p \\leq 0.5$, it's classified as the negative class.\n",
    "\n",
    "### Differences from Linear Regression\n",
    "\n",
    "1. **Output Type:** The most significant difference is the output type. Linear regression predicts a continuous outcome (e.g., house prices), while logistic regression predicts a probability for a binary outcome (e.g., whether a customer will buy a product or not).\n",
    "\n",
    "2. **Equation Form:** The equations differ fundamentally. Linear regression uses a linear equation to predict the continuous outcome, while logistic regression models the log-odds of the probability of the positive class using a logistic (S-shaped) curve.\n",
    "\n",
    "3. **Residuals:** In linear regression, the residuals (the differences between predicted and actual values) follow a normal distribution. In logistic regression, the residuals don't follow a normal distribution but rather follow a binomial distribution.\n",
    "\n",
    "4. **Assumptions:** Linear regression assumes linearity, constant variance, and normality of residuals. Logistic regression does not make these same assumptions because it models probabilities.\n",
    "\n",
    "Logistic regression is specifically designed for binary classification tasks, and its output is a probability estimate. The interpretation of coefficients in logistic regression is based on log-odds, making it well-suited for problems where you want to predict the probability of an event occurring or not occurring.\n",
    "\n",
    "## How Logistic Regression Works\n",
    "\n",
    "**Likelihood Function**\n",
    "\n",
    "- Logistic regression models the probability of the positive class (\\(y = 1\\)) as:\n",
    "  $$\n",
    "  P(y = 1 | X) = \\frac{1}{1 + e^{-X\\beta}}, \\quad P(y = 0 | X) = 1 - P(y = 1 | X).\n",
    "  $$\n",
    "- The likelihood of the observed data is:\n",
    "  $$\n",
    "  \\mathcal{L}(\\beta) = \\prod_{i=1}^n P(y_i | X_i) = \\prod_{i=1}^n \\left[ p_i^{y_i} (1 - p_i)^{1 - y_i} \\right],\n",
    "  $$\n",
    "  where $p_i = P(y_i = 1 | X_i)$.\n",
    "- The log-likelihood simplifies optimization:\n",
    "  $$\n",
    "  \\log \\mathcal{L}(\\beta) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right].\n",
    "  $$\n",
    "\n",
    "**Optimization Problem**\n",
    "\n",
    "- The goal is to find the coefficients $\\beta$ that maximize the log-likelihood:\n",
    "  $$\n",
    "  \\hat{\\beta} = \\arg \\max_\\beta \\log \\mathcal{L}(\\beta).\n",
    "  $$\n",
    "- The log-likelihood is concave, ensuring a global maximum, but it's nonlinear, so no closed-form solution exists.\n",
    "\n",
    "- **Gradient of the log-likelihood**:\n",
    "  $$\n",
    "  \\frac{\\partial \\log \\mathcal{L}(\\beta)}{\\partial \\beta} = \\sum_{i=1}^n (y_i - p_i) X_i.\n",
    "  $$\n",
    "- The gradient points in the direction to adjust $\\beta$ to improve the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1bbd28-a79e-4ad9-9dc5-87b25cef6df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = [\"RV\"]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "\n",
    "# Initialize Logistic Regression Model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logistic_model.fit(X, y)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfdcde4-b20a-4bd4-8ee3-9c5af8db14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40072a8-266f-4746-a8cd-51d6d0d77352",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349320e-2f52-4b0d-ba88-8b98b3832b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ea32c-fb63-4a9b-9833-82728ddb9170",
   "metadata": {},
   "source": [
    "**Inspecting the Parameters**\n",
    "\n",
    "One can access the estimated coefficients and the intercept of the logistic regression model using the coef_ and intercept_ attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9e656-86b0-4321-a54c-34018c70cc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "coef = logistic_model.coef_[0]\n",
    "print(f\"Coefficient for RV: {coef}\")\n",
    "\n",
    "# Intercept\n",
    "intercept = logistic_model.intercept_[0]\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98634657-0ade-43fa-ae01-c95fbef6c8c8",
   "metadata": {},
   "source": [
    "**Checking for Statistical Significance**\n",
    "\n",
    "To check the statistical significance of the coefficients, you can perform a hypothesis test. This usually involves a **Wald test** in the context of logistic regression. \n",
    "\n",
    "**Null Hypothesis (H0):** $\\beta_1 = 0$\n",
    "\n",
    "**Alternative Hypothesis (H1):** $\\beta_1 \\neq 0$\n",
    "\n",
    "\n",
    "$$ \\text{Wald Statistic} = \\frac{(\\hat{\\beta}_1 - 0)^2}{\\text{Var}(\\hat{\\beta}_1)} $$\n",
    "\n",
    "The Wald test is already used with linear regression estimations, as we have seen in the previous lecture. However, in logistic regression, the estimated coefficients $ \\hat{\\beta}_1$ are related to the log-odds of the dependent variable, and the variance calculation involves the complex structure of the logistic model. The test statistic follows a chi-squared distribution with 1 degree of freedom.\n",
    "\n",
    "\n",
    "You can use the statsmodels library to fit the logistic regression model and obtain the p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b759d7f-e1ea-4c31-b358-7008e467193d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a constant to the features (for the intercept)\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "logit_model = sm.Logit(y, X_sm)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Summary of the regression, including p-values\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476e477-eb5a-43b8-9e67-1847a9164e31",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:24px\">\n",
    "    <span style=\"color:red\">How should you choose between statsmodels and scikit-learn?</span>\n",
    "</div>\n",
    "\n",
    "\n",
    "Evaluate the performance of a model through Accuracy, Precision, Recall and F1 Score metrics and provides a brief explanation of the Confusion Matrix. \n",
    "Once you have built your model, the most important question that arises is how good is your model? So, evaluating your model is the most important task in the data science work which delineates how good your predictions are.\n",
    "\n",
    "Remind the fllowing concepts:\n",
    "\n",
    "- True Positives (TP) - These are the correctly predicted positive values which means that the value of actual class is 1 and the value of predicted class is also 1.\n",
    "\n",
    "- True Negatives (TN) - These are the correctly predicted negative values which means that the value of actual class is not 1 and value of predicted class is also not 1. \n",
    "\n",
    "False positives and false negatives, these values occur when your actual class contradicts with the predicted class.\n",
    "\n",
    "- False Positives (FP) – When actual class is not 1 and predicted class is 1. \n",
    "\n",
    "- False Negatives (FN) – When actual class is 1 but predicted class in not 1. \n",
    "\n",
    "Once you understand these four concepts then we can calculate Accuracy, Precision, Recall and F1 score.\n",
    "\n",
    "- Accuracy - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model.\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}$$\n",
    "\n",
    "- Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all of the observation labelled as 1, how many actually are  1? High precision relates to the low false positive rate. \n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "- Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the observation that belongs to class 1, how many did we predicted correctly?\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "- F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution as in our case. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall.\n",
    "\n",
    "$$F1 Score = \\frac{2*(Recall * Precision)}{(Recall + Precision)}$$\n",
    "\n",
    "So, whenever you build a model, these concepts should help you to figure out how good your model has performed.\n",
    "\n",
    "Look [here](https://developers.google.com/machine-learning/crash-course/classification/thresholding) and [here](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) for a better understanding of the next metrics we are going to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2e9ae-2c94-48d1-baa8-22722ac0bdde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = [\"RV\", \"TBill1Y_ret\", \"TBill3M_ret\"]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "\n",
    "# Initialize Logistic Regression Model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logistic_model.fit(X, y)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83955bce-ee2f-4fab-ae1c-163a348c90af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict probabilities and select those for the positive class (y = 1) for each observation in the test set. It is used later for the ROC-AUC calculation.\n",
    "y_probs = logistic_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Print a report summarizing the precision, recall, and F1-score for each class. It provides a quick overview of how well the model is performing for each class.\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "# This computes the Area Under the Receiver Operating Characteristic Curve (ROC-AUC). A value closer to 1 indicates better classification performance.\n",
    "roc_auc = roc_auc_score(y, y_probs)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "# This calculates the False Positive Rate (FPR) and True Positive Rate (TPR) for various threshold values, which are used to plot the ROC curve.\n",
    "fpr, tpr, _ = roc_curve(y, y_probs)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417886-7139-4893-a29b-3c17df1d23b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to fit a logistic regression model and plot the ROC\n",
    "def plot_roc(model, X, y, label, ax):\n",
    "    model.fit(X, y)\n",
    "    y_probs = model.predict_proba(X)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y, y_probs)\n",
    "    roc_auc = roc_auc_score(y, y_probs)\n",
    "    ax.plot(fpr, tpr, label=f\"{label} (AUC = {roc_auc:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706c243-c5bc-4ec2-8ae4-9a51cb44fe9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99c07c-aadf-4a55-b6d9-ed47686b0c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "features = [\"RV\"]\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "model1 = LogisticRegression()\n",
    "plot_roc(model1, X,y, \"LR1\", ax)\n",
    "\n",
    "features = [\"RV\", \"TBill1Y_ret\"]\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "model2 = LogisticRegression(penalty=\"l2\", solver=\"liblinear\")\n",
    "plot_roc(model2,  X,y, \"LR2\", ax)\n",
    "\n",
    "features = [\"RV\", \"TBill1Y_ret\", \"TBill3M_ret\"]\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "model3 = LogisticRegression()\n",
    "plot_roc(model3, X,y, \"LR3\", ax)\n",
    "\n",
    "features = [\n",
    "    \"TBill3M\",\n",
    "    \"TBill1Y\",\n",
    "    \"Oil\",\n",
    "    \"RV\",\n",
    "    \"Gold\",\n",
    "    \"SP_close\",\n",
    "    \"SP_volume\",\n",
    "    \"Holiday\",\n",
    "    \"weekday\",\n",
    "    \"TBill3M_ret\",\n",
    "    \"TBill1Y_ret\",\n",
    "    \"Oil_ret\",\n",
    "    \"Gold_ret\",\n",
    "    \"SP_volume_ret\",\n",
    "    \"Return_close_lag1\",\n",
    "    \"Return_close_lag2\",\n",
    "    \"Return_close_lag3\",\n",
    "]\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "model4 = LogisticRegression()\n",
    "plot_roc(model4,  X,y, \"LR4\", ax)\n",
    "\n",
    "\n",
    "# Add random classifier line and labels\n",
    "ax.plot([0, 1], [0, 1], \"k--\")\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"Receiver Operating Characteristic\")\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c3396-37bd-42a7-b173-97891c92924c",
   "metadata": {},
   "source": [
    "## Evaluation of Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8af32e-0479-49be-942b-d35ecd35d123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a25f2-366d-4490-8233-b1712bf95e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f49f8f-71de-4752-babd-273a14456298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84a060-1368-4a68-92aa-5a8b5c8c497f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cf18b9-d057-462e-97a8-6827203df524",
   "metadata": {},
   "source": [
    "**CONFUSION MATRIX**: true values are displayed by column, while predicted value are displayed by row. The entry [0,0] represents the number of negative output in class 1 that the model predict correctly, while the entry [1,1] represents the number of positive output in class 1 that the model predict correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bcb31-c2a3-422d-b3fe-2420bf956e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = [\"RV\", \"TBill1Y_ret\", \"TBill3M_ret\"]\n",
    "X = df[features]\n",
    "y = df[\"Ret_binary\"]\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X, y)\n",
    "y_pred = logistic_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c7093-8e35-4512-9c79-311cc81e7081",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ff166-d6e1-427c-afff-ea5017711011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8ad88-9762-4f2f-b09f-8d337a769003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74033f17-7b74-45cf-befb-b3eeee545c15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eeba09-86ad-40de-96d9-a8aaff60249a",
   "metadata": {},
   "source": [
    "# Logistic Regression for Multiclass Classification\n",
    "\n",
    "Multiclass classification and binary classification are two distinct tasks in supervised learning, and logistic regression can be adapted to handle both. Here's a comparison and description of performing multiclass classification vs. binary classification using logistic regression:\n",
    "\n",
    "**Binary Classification**\n",
    "In binary classification, there are only two possible outcomes or classes. Logistic regression models the probability that the target variable belongs to a particular category. It uses the logistic function to squeeze the output of a linear equation between 0 and 1. The class label prediction is then made based on whether the probability is above or below a certain threshold (usually 0.5).\n",
    "\n",
    "**Multiclass Classification**\n",
    "Multiclass classification extends the concept of binary classification to more than two classes. In the context of logistic regression, this can be done in several ways:\n",
    "\n",
    "- *One-vs-All (OvA) or One-vs-Rest (OvR)*: In this approach, separate binary logistic regression models are trained for each class against all other classes. If there are $k$ classes, $k$ different binary logistic regression models are trained. Predictions are made by evaluating all $k$ models and choosing the class for which the corresponding model gives the highest probability.\n",
    "\n",
    "- *Softmax Regression (Multinomial Logistic Regression)*: Softmax regression generalizes logistic regression to multiple classes. Instead of modeling just one binary response, the softmax function is used to model the multinomial probability distribution over the classes. The output is a probability for each class, and the predicted class label is the one with the highest probability.\n",
    "\n",
    "\n",
    "**Binary Classification**: Simpler and suitable when there are only two classes to distinguish between.\n",
    "\n",
    "**Multiclass Classification**: More complex, as it deals with multiple classes. Requires special handling through techniques like OvA/OvR or softmax regression.\n",
    "\n",
    "*Interpretability*: While binary logistic regression provides direct insights into the effect of each feature on the odds of belonging to one class, multiclass logistic regression, especially when using the softmax function, may be less straightforward to interpret. In multiclass classification, evaluation metrics such as accuracy, confusion matrix, and multiclass ROC-AUC become more complex, as they must account for multiple classes.\n",
    "\n",
    "\n",
    "Here is what we are going to do now:\n",
    "- Analyze the Distribution: First, you'll want to understand the distribution of the Return_close variable. You can use descriptive statistics or visualization methods to get an overview of the data.\n",
    "\n",
    "- Choose the Bin Edges: Based on your analysis, you can decide how to segment the data. For example, you might want to have three classes: \"Negative Return\", \"No Gain\", and \"Positive Return\". You'll need to define the edges of the bins that separate these classes.\n",
    "\n",
    "- Apply `pd.cut` with Custom Bin Edges to transform the continuous `Return_close` variable into categorical classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04851b0-37c2-4514-af95-7fc17dfb78b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Return_close\"].describe(percentiles=[0.1, 0.25, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a90fa-523b-469d-9702-a52f3d06d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Multiclass_Target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd3526-fefc-4ca4-9764-b06229b1a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea5437-71c9-4608-a7c8-6391729c1ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform 'Return_close' into a multiclass target variable\n",
    "# Example: Negative Return, No Gain, Positive Return\n",
    "df[\"Multiclass_Target\"] = pd.cut(\n",
    "    df[\"Return_close\"],\n",
    "    bins=[-float(\"inf\"), -0.5, 0.5, float(\"inf\")],\n",
    "    labels=[\"Negative Return\", \"No Gain\", \"Positive Return\"],\n",
    ")\n",
    "\n",
    "\n",
    "features = [\"RV\", \"TBill1Y_ret\"]\n",
    "X = df[features]\n",
    "y = df[\"Multiclass_Target\"]\n",
    "\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000, multi_class=\"auto\")\n",
    "logistic_model.fit(X, y)\n",
    "y_pred = logistic_model.predict(X)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdcdfc0-55a1-4da8-a7d4-66bfa92da460",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f221da-3f19-4610-9b80-d39748095cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Multiclass_Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0158e87-3753-4852-aca7-00b999e5ffcd",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:24px\">\n",
    "    <span style=\"color:red\">How do we know if we are using One-vs-Rest (OvR) or Softmax Regression?</span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53257d7-c3c9-4a0a-9264-d522693f2fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa25b1-8864-475b-9534-02ed636d2bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc06925-85f1-4bf5-9a91-edeaf8fca93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee44c0-88d2-4018-8128-56bc92df588f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0e7be-6137-4e05-b731-29da536ba822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a8fa6-6ffd-4593-b0d3-b3e15115c323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech_lectures",
   "language": "python",
   "name": "fintech_lectures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
